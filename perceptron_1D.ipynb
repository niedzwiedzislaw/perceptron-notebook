{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuron implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Neuron:\n",
    "    w: float\n",
    "    b: float\n",
    "    f: Callable[[float], float]\n",
    "\n",
    "    def activation(self, x):\n",
    "        return self.f(self.w * x + self.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-dimensional array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "@np.vectorize\n",
    "def we_want_bigger_than_two(x):\n",
    "    return 1 if x > 2 else 0\n",
    "\n",
    "\n",
    "def sample_data(size):\n",
    "    input = np.sort((np.random.rand(size) - 0.5) * 10)\n",
    "    classification = we_want_bigger_than_two(input)\n",
    "    return input, classification\n",
    "\n",
    "input, classification = sample_data(40)\n",
    "plt.scatter(input, np.zeros(input.size), c=classification)\n",
    "plt.axvline(x = 2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 1 if x > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(input, classification):\n",
    "    net = Neuron(0, 0, f)\n",
    "    smart = False\n",
    "    while not smart:\n",
    "        smart = True\n",
    "        for i in range(input.size):\n",
    "            answer = net.activation(input[i])\n",
    "            net.w = net.w + (classification[i] - answer) * input[i]\n",
    "            net.b = net.b + (classification[i] - answer)\n",
    "            smart = smart and answer == classification[i]\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "input, classification = sample_data(7)\n",
    "net = perceptron(input, classification)\n",
    "m = np.matrix((input, [net.activation(i) for i in input], classification))\n",
    "print(pd.DataFrame(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualized with graphs\n",
    "\n",
    "On the left:\n",
    "- green ticks show expected value\n",
    "- blue ticks show current evaluation\n",
    "- blue solid line show how network calculated values before activation function f is applied\n",
    "- vertical dotted line show where data should be separated\n",
    "\n",
    "On the right:\n",
    "- plot of historical number of errors in the neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.markers import CARETUP, CARETDOWN\n",
    "from IPython import display\n",
    "\n",
    "def perceptron(input, classification):\n",
    "    fig, (ax_calc, ax_error) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(16, 9)\n",
    "\n",
    "\n",
    "    def plot(answer, error, net):\n",
    "        @np.vectorize\n",
    "        def value(i):\n",
    "            return net.w * i + net.b\n",
    "\n",
    "        ax_calc.cla()\n",
    "        ax_calc.set_title(f'Network {net}')\n",
    "        ax_error.set_title('Error')\n",
    "        ax_calc.set_xlim([input[0], input[input.size - 1]])\n",
    "        ax_calc.set_ylim([-3, 3])\n",
    "        ax_calc.axvline(x = 2, dashes=(1, 1), linewidth=1)\n",
    "        ax_calc.plot(input, value(input))\n",
    "        ax_calc.scatter(input, classification, color='green', marker=CARETUP)\n",
    "        ax_calc.scatter(input, answer, color='blue', marker=CARETDOWN)\n",
    "        ax_error.plot(error)\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "\n",
    "    net = Neuron(0, 0, f)\n",
    "    smart = False\n",
    "    errors = []\n",
    "    answers = np.zeros(input.size)\n",
    "    while not smart:\n",
    "        smart = True\n",
    "        for i in range(input.size):\n",
    "            answers[i] = net.activation(input[i])\n",
    "            net.w = net.w + (classification[i] - answers[i]) * input[i]\n",
    "            net.b = net.b + (classification[i] - answers[i])\n",
    "            errors.append(np.square(classification - answers).sum())\n",
    "            smart = smart and answers[i] == classification[i]\n",
    "            # Plot graphs after every single example because we don't expect learning to take very long time\n",
    "            plot(answers, errors, net)\n",
    "\n",
    "    return net\n",
    "\n",
    "input, classification = sample_data(40)\n",
    "net = perceptron(input, classification)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
