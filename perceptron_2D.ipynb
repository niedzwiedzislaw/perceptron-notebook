{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuron with more weights, works with two input values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Callable\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Neuron:\n",
    "    w: List[float]\n",
    "    b: float\n",
    "    f: Callable[[float], float]\n",
    "\n",
    "    def activation(self, v):\n",
    "        return f(self.w[0] * v[0] + self.w[1] * v[1] + self.b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@np.vectorize\n",
    "def f(x):\n",
    "    return 1 if x > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "input = np.random.rand(1000, 2)\n",
    "\n",
    "def we_want_only_those(x):\n",
    "    return 1 if x[0] > x[1] + 0.2 else 0\n",
    "\n",
    "classification = np.apply_along_axis(we_want_only_those, 1, input)\n",
    "x, y = input.T\n",
    "plt.scatter(x, y, c=classification)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(input, classification):\n",
    "    net = Neuron([0, 0], 0, f)\n",
    "    smart = False\n",
    "    while not smart:\n",
    "        smart = True\n",
    "        answers = np.zeros(input.size)\n",
    "        for i, v in enumerate(input):\n",
    "            answer = net.activation(v)\n",
    "            net.w[0] = net.w[0] + (classification[i] - answer) * v[0]\n",
    "            net.w[1] = net.w[1] + (classification[i] - answer) * v[1]\n",
    "            net.b = net.b + (classification[i] - answer)\n",
    "            smart = smart and answers[i] == classification[i]\n",
    "    return net\n",
    "\n",
    "net = perceptron(input, classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation with gaphs\n",
    "On the left:\n",
    "- color-coded current evaluation\n",
    "- dashed line shows expected separation\n",
    "\n",
    "On the right:\n",
    "- historical number of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import time\n",
    "\n",
    "def perceptron(input, classification):\n",
    "    fig, (ax_calc, ax_error) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(16, 9)\n",
    "    x, y = input.T\n",
    "\n",
    "    def plot(answer, error, net):\n",
    "        ax_calc.cla()\n",
    "        ax_calc.set_xlim([0, 1])\n",
    "        ax_calc.set_ylim([0, 1])\n",
    "        ax_calc.axline((0.2, 0), (1, 0.8), dashes=(1, 1), linewidth=1)\n",
    "        ax_calc.set_title(f'Network {net}')\n",
    "        ax_error.set_title('Error')\n",
    "        ax_calc.scatter(x, y, c=answer, marker='o')\n",
    "        ax_error.plot(error)\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        # time.sleep(0.5) # Just to make the graphs easier to track by eye\n",
    "\n",
    "    d = 0.1\n",
    "    net = Neuron(np.random.rand(input.shape[1]), 0, f)\n",
    "    smart = False\n",
    "    errors = []\n",
    "    answers = np.zeros(input.shape[0])\n",
    "    while not smart:\n",
    "        smart = True\n",
    "        for i, v in enumerate(input):\n",
    "            answers[i] = net.activation(v)\n",
    "            net.w[0] = net.w[0] + (classification[i] - answers[i]) * v[0]\n",
    "            net.w[1] = net.w[1] + (classification[i] - answers[i]) * v[1]\n",
    "            net.b = net.b + d * (classification[i] - answers[i])\n",
    "            errors.append(np.square(classification - answers).sum())\n",
    "            smart = smart and answers[i] == classification[i]\n",
    "\n",
    "        # Plot graphs only after whole dataset is processed because otherwise it just takes to long\n",
    "        plot(answers, errors, net)\n",
    "    return net\n",
    "\n",
    "net = perceptron(input, classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data set impossible to solve by single perceptron\n",
    "Not separable by a single line and thus impossible to solve.\n",
    "After running this notebook cell you can go back to the previous one and see how perceptron fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "input = np.random.rand(1000, 2)\n",
    "\n",
    "def we_want_only_those(x):\n",
    "    return 1 if x[0] > x[1] + 0.3 or x[0] < x[1] - 0.3 else 0\n",
    "\n",
    "classification = np.apply_along_axis(we_want_only_those, 1, input)\n",
    "x, y = input.T\n",
    "plt.scatter(x, y, c=classification)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
